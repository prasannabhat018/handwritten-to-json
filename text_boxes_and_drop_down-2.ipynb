{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121 1911\n",
      "{(471, 53, 95, 26), (192, 440, 59, 25), (197, 482, 57, 25), (363, 54, 93, 24), (103, 135, 84, 24), (153, 415, 124, 28)}\n"
     ]
    }
   ],
   "source": [
    "large = cv2.imread('hwr-form-6.jpg')\n",
    "print(large.shape[0],large.shape[1])\n",
    "h = large.shape[0]\n",
    "w = large.shape[1]\n",
    "rgb = cv2.resize(large, (725, 660))\n",
    "small = cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)\n",
    "img = large\n",
    "img2 = small\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "kernel = np.ones((1, 9), np.uint8)\n",
    "grad = cv2.morphologyEx(small, cv2.MORPH_GRADIENT, kernel)\n",
    "_, bw = cv2.threshold(grad, 0, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11, 1))\n",
    "connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (12,1))\n",
    "#connected = cv2.dilate(connected,kernel2, iterations = 1)\n",
    "\n",
    "cv2.imwrite(\"/Users/nishith/cv/Lib/site-packages/i1.jpg\",connected)\n",
    "# using RETR_EXTERNAL instead of RETR_CCOMP\n",
    "contours, hierarchy = cv2.findContours(connected.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "mask = np.zeros(bw.shape, dtype=np.uint8)\n",
    "count=0\n",
    "\n",
    "text = \"\"\n",
    "TEXT = set()\n",
    "for idx in range(len(contours)):\n",
    "    x, y, w, h = cv2.boundingRect(contours[idx])\n",
    "    mask[y:y+h, x:x+w] = 0\n",
    "    cv2.drawContours(mask, contours, idx, (255, 255, 255), -1)\n",
    "    r = float(cv2.countNonZero(mask[y:y+h, x:x+w])) / (w * h)\n",
    "    \n",
    "    if r > 0.4 and w > 8 and h > 8 and w>2*h:\n",
    "        #cv2.rectangle(rgb, (x-1, y-1), (x+w-1, y+h-1), (255, 255, 255), -1)\n",
    "        m = np.mean(rgb[:, :]) + 5\n",
    "        TEXT.add((x,y,w,h))\n",
    "        #cv2.imwrite(\"words/\"+str(idx)+\".jpg\", rgb[y-10:y+h+5, x-5:x+w+5])\n",
    "        for j in range(x-5, x+w+5):\n",
    "            for i in range(y-10, y+h+5):\n",
    "                rgb[i,j] = m\n",
    "\n",
    "cv2.imwrite(\"/Users/nishith/cv/Lib/site-packages/mod_img.jpg\",rgb)\n",
    "cv2.imshow('rects', rgb)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"mod_img.jpg\")\n",
    "img3 = np.copy(img)\n",
    "img2 = img\n",
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "grey = cv2.GaussianBlur(grey,(21,21), 0)\n",
    "th = cv2.adaptiveThreshold(grey,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,33,2)\n",
    "kernel = np.ones((1,5),np.uint8)\n",
    "\n",
    "th = 255 - th\n",
    "\n",
    "nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(th, None, None, None, 4, cv2.CV_32S)\n",
    "areas = stats[1:,cv2.CC_STAT_AREA]\n",
    "result = np.zeros((labels.shape), np.uint8)\n",
    "for i in range(0, nlabels - 1):\n",
    "    if areas[i] >= 210:   #keep\n",
    "        result[labels == i + 1] = 255\n",
    "\n",
    "#cv2.imshow(\"Binary\", binary_map)\n",
    "result = 255-result\n",
    "\n",
    "cv2.imwrite(\"inter1.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours, hierarchy = cv2.findContours(result, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours_poly = [None]*len(contours)\n",
    "boundRect = [None]*len(contours)\n",
    "centroid = set()\n",
    "\n",
    "\n",
    "for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv2.approxPolyDP(c, 3, True)\n",
    "        boundRect[i] = cv2.boundingRect(contours_poly[i])\n",
    "        \n",
    "        \n",
    "for i in boundRect:\n",
    "    if i[2]<=10 or i[3]<=10:\n",
    "        boundRect.remove(i)\n",
    "    if i[2]==img3.shape[1] and i[3]==img3.shape[0]:\n",
    "        boundRect.remove(i)\n",
    "        \n",
    "i=0\n",
    "j=0\n",
    "while i < len(boundRect):\n",
    "    centroid = (boundRect[i][0] + boundRect[i][2]/2, boundRect[i][1] + boundRect[i][3]/2)\n",
    "    j = i+1 \n",
    "    while j < len(boundRect):\n",
    "        if abs(boundRect[j][0]+boundRect[j][2]/2 -centroid[0])<5 and abs(boundRect[j][1]+boundRect[j][3]/2 -centroid[1])<5: \n",
    "            boundRect.remove(boundRect[j])\n",
    "            break\n",
    "        else:\n",
    "                j+=1\n",
    "    i += 1\n",
    "\n",
    "temp = list()        #stores Radio buttons ,Check boxes and No.s  \n",
    "buttons = list()     #stores Buttons\n",
    "images = list()\n",
    "\n",
    "for i in TEXT.copy():\n",
    "    x1,y1,w1,h1 = i[:]\n",
    "    for j in boundRect:\n",
    "        x,y,w,h = j[:]\n",
    "        if y1>=y and x<=x1 and y+h>=y1+h1 and x1+w1<=x+w:\n",
    "            buttons.append(j)\n",
    "            boundRect.remove(j)\n",
    "            TEXT.remove(i)\n",
    "            #cv2.rectangle(img3, (j[0], j[1]), (j[0]+j[2], j[1]+j[3]),(0,0,255), 2)\n",
    "            break\n",
    "    \n",
    "    \n",
    "for i in TEXT:\n",
    "    c1 =  i[1]+i[3]/2\n",
    "    for j in boundRect:\n",
    "        c = j[1]+j[3]/2\n",
    "        if abs(c1-c)<=10 and i[0]>j[0]:\n",
    "            temp.append(j)\n",
    "            boundRect.remove(j)\n",
    "            images.append(img3[j[1]-10: j[1]+j[3]+10, j[0]-10: j[0]+j[2]+10])\n",
    "            #cv2.rectangle(img3, (j[0], j[1]), (j[0]+j[2], j[1]+j[3]),(0,0,255), 2)\n",
    "            break\n",
    "\n",
    "        \n",
    "cv2.imshow(\"IMAGE\", img3)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(\"4mbCAPS.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ig in images:\n",
    "    cv2.imshow(\"IMAGE\", ig)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                4644      \n",
      "=================================================================\n",
      "Total params: 330,596\n",
      "Trainable params: 329,764\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "p = 0\n",
    "k = 0\n",
    "radio_buttons = list()\n",
    "check_boxes = list()\n",
    "numbers = list()\n",
    "for ig1 in images:\n",
    "    ig1 = cv2.cvtColor(ig1, cv2.COLOR_BGR2GRAY)\n",
    "    ret2,char = cv2.threshold(ig1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    w,h=char.shape\n",
    "    d=abs(w-h)\n",
    "    if d>1:\n",
    "        if w>h:\n",
    "            new=np.full((w,w), 255, dtype=np.uint8)\n",
    "            new[0:w,d//2:d//2+h]=char\n",
    "        else:\n",
    "            new=np.full((h,h), 255, dtype=np.uint8)\n",
    "            new[d//2:d//2+w,0:h]=char\n",
    "        char=new\n",
    "    char=cv2.resize(char,(28-2*p,28-2*p))\n",
    "    new=np.full((28,28), 255, dtype=np.uint8)\n",
    "    new[p:28-p,p:28-p]=char\n",
    "    char=new\n",
    "    char=char.reshape(1,28,28,1)\n",
    "    classes = model.predict(char)\n",
    "    letter = mapping[np.argmax(classes[0])]\n",
    "    if ord(letter)<=57 and ord(letter)>=49:\n",
    "        numbers.append(temp[k])\n",
    "    elif ord(letter)==ord(\"Q\") or ord(letter)==ord(\"O\") or ord(letter)==ord(\"0\"):\n",
    "        radio_buttons.append(temp[k])\n",
    "    else:\n",
    "        check_boxes.append(temp[k])\n",
    "    k+=1\n",
    "    \n",
    "    #cv2.imshow(\"IMAGE\", ig1)\n",
    "    #cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in radio_buttons:\n",
    "    cv2.rectangle(img3, (j[0],j[1]), (j[0]+j[2],j[1]+j[3]), (255,0,0), 1)\n",
    "for j in check_boxes:\n",
    "        cv2.rectangle(img3, (j[0],j[1]), (j[0]+j[2],j[1]+j[3]), (0,255,0), 1)\n",
    "for j in numbers:\n",
    "        cv2.rectangle(img3, (j[0],j[1]), (j[0]+j[2],j[1]+j[3]), (0,0,255), 1)\n",
    "cv2.imshow(\"I\", img3)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
